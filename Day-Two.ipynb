{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day Two\n",
    "\n",
    "Before we start, make sure you import nltk into your new notebook, as well as numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "In general, Python regards a text file as a single long string of characters. Tokenization breaks text into words that the computer can understand as discrete units. Here is an example of one of NLTK's tokenizers at work:\n",
    "\n",
    "First, we import the special twitter tokenizer from nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize.casual import (TweetTokenizer, casual_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, save a tweet as a variable. In computer programming, variables are data (e.g. “PM @TurnbullMalcolm: Under changes agreed...”) paired with an associated symbolic name or identifier (e.g. 'tweet' in the code below). We'll learn more about these later, but here's how you assign data a variable. I've given my tweet the variable name 'tweet'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet = \"PM @TurnbullMalcolm: Under changes agreed to today, it's 'inconceivable' Brighton terrorist would have got parole. @theheraldsun #auspol\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Call' (programmer speak) your tweet to check it's saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PM @TurnbullMalcolm: Under changes agreed to today, it's 'inconceivable' Brighton terrorist would have got parole. @theheraldsun #auspol\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use our special tweet tokenizer to tell the computer to recognise my tweet as a list of words, not a long string of characters. To do this a create and save another variable. This is common practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_tokens = casual_tokenize(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now call your new variable and observe how it differs from when you called the first variable 'tweet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PM',\n",
       " '@TurnbullMalcolm',\n",
       " ':',\n",
       " 'Under',\n",
       " 'changes',\n",
       " 'agreed',\n",
       " 'to',\n",
       " 'today',\n",
       " ',',\n",
       " \"it's\",\n",
       " \"'\",\n",
       " 'inconceivable',\n",
       " \"'\",\n",
       " 'Brighton',\n",
       " 'terrorist',\n",
       " 'would',\n",
       " 'have',\n",
       " 'got',\n",
       " 'parole',\n",
       " '.',\n",
       " '@theheraldsun',\n",
       " '#auspol']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_\n",
    "Compare the output of the variable sentence and the variable words. Notice that in the latter, the words are represented as a list._\n",
    "\n",
    "### Challenge!\n",
    "Try running `tweet[1]` and the `tweet_tokens[1]` in separate cells. Observe what happens. What unit is each variable count? Try changing the numbers in the square brackets. Have you noticed that Python starts counting at 0?\n",
    "Using the `casual_tokenize()` function of nltk has changed our sentence into a list of words that can be searched, rather than characters. We saved our initial sentence as ‘tweet’ and the list of tokenised words as ‘tweet_tokens’, using numbers within the square brackets allows us to ask the computer what value (character or word) is at a particular position in the list. This is called indexing. A list in computer programming is an abstract data type that represents a countable number of ordered values. You can learn more about list function and data structures in Python [here](https://docs.python.org/3/tutorial/datastructures.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@TurnbullMalcolm'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_tokens[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PM'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_tokens[0] #noticed that Python starts counting at 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
