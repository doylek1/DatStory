{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day Two\n",
    "\n",
    "Before we start, make sure you import nltk into your new notebook, as well as numpy and the example texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy\n",
    "%matplotlib inline\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "In general, Python regards a text file as a single long string of characters. Tokenization breaks text into words that the computer can understand as discrete units. Here is an example of one of NLTK's tokenizers at work:\n",
    "\n",
    "First, we import the special twitter tokenizer from nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize.casual import (TweetTokenizer, casual_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, save a tweet as a variable. In computer programming, variables are data (e.g. “PM @TurnbullMalcolm: Under changes agreed...”) paired with an associated symbolic name or identifier (e.g. 'tweet' in the code below). We'll learn more about these later, but here's how you assign data a variable. I've given my tweet the variable name 'tweet'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet = \"PM @TurnbullMalcolm: Under changes agreed to today, it's 'inconceivable' Brighton terrorist would have got parole. @theheraldsun #auspol\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Call' (programmer speak) your tweet to check it's saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PM @TurnbullMalcolm: Under changes agreed to today, it's 'inconceivable' Brighton terrorist would have got parole. @theheraldsun #auspol\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use our special tweet tokenizer to tell the computer to recognise my tweet as a list of words, not a long string of characters. To do this a create and save another variable. This is common practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweet_tokens = casual_tokenize(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now call your new variable and observe how it differs from when you called the first variable 'tweet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PM',\n",
       " '@TurnbullMalcolm',\n",
       " ':',\n",
       " 'Under',\n",
       " 'changes',\n",
       " 'agreed',\n",
       " 'to',\n",
       " 'today',\n",
       " ',',\n",
       " \"it's\",\n",
       " \"'\",\n",
       " 'inconceivable',\n",
       " \"'\",\n",
       " 'Brighton',\n",
       " 'terrorist',\n",
       " 'would',\n",
       " 'have',\n",
       " 'got',\n",
       " 'parole',\n",
       " '.',\n",
       " '@theheraldsun',\n",
       " '#auspol']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_\n",
    "Compare the output of the variable sentence and the variable words. Notice that in the latter, the words are represented as a list._\n",
    "\n",
    "### Challenge!\n",
    "Try running `tweet[1]` and the `tweet_tokens[1]` in separate cells. Observe what happens. What unit is each variable count? Try changing the numbers in the square brackets. Have you noticed that Python starts counting at 0?\n",
    "Using the `casual_tokenize()` function of nltk has changed our sentence into a list of words that can be searched, rather than characters. We saved our initial sentence as ‘tweet’ and the list of tokenised words as ‘tweet_tokens’, using numbers within the square brackets allows us to ask the computer what value (character or word) is at a particular position in the list. This is called indexing. A list in computer programming is an abstract data type that represents a countable number of ordered values. You can learn more about list function and data structures in Python [here](https://docs.python.org/3/tutorial/datastructures.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@TurnbullMalcolm'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_tokens[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PM'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_tokens[0] #noticed that Python starts counting at 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lists\n",
    "Python treats a text as a long list of words. First, we'll make some lists of our own, to give you an idea of how a list behaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1\n",
    "len(sent1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The opening sentences of each of our texts have been pre-defined for you. You can inspect them by typing in `sent2` etc.\n",
    "You can add lists together, creating a new list containing all the items from both lists. You can do this by typing out the two lists or you can add two or more pre-defined lists. This is called concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fellow',\n",
       " '-',\n",
       " 'Citizens',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Senate',\n",
       " 'and',\n",
       " 'of',\n",
       " 'the',\n",
       " 'House',\n",
       " 'of',\n",
       " 'Representatives',\n",
       " ':',\n",
       " 'Call',\n",
       " 'me',\n",
       " 'Ishmael',\n",
       " '.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent4 + sent1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add an item to the end of a list by appending. When we ``append()``, the list itself is updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Call', 'me', 'Ishmael', '.', 'Please']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1.append('Please')\n",
    "sent1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Indexing Lists\n",
    "We can navigate this list with the help of indexes. Just as we can find out the number of times a word occurs in a text, we can also find where a word first occurs. We can navigate to different points in a text without restriction, so long as we can describe where we want to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173\n"
     ]
    }
   ],
   "source": [
    "print(text4.index('awaken'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works in reverse as well. We can ask Python to locate the 158th item in our list (note that we use square brackets here, not parentheses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "awaken\n"
     ]
    }
   ],
   "source": [
    "print(text4[173])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as pulling out individual items from a list, indexes can be used to pull out selections of text from a large corpus to inspect. We call this slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['U86', 'thats', 'why', 'something', 'like', 'gamefly', 'is', 'so', 'good', 'because', 'you', 'can', 'actually', 'play', 'a', 'full', 'game', 'without', 'buying', 'it']\n"
     ]
    }
   ],
   "source": [
    "print(text5[16715:16735])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we're asking for the beginning or end of a text, we can leave out the first or second number. For instance, [:5] will give us the first five items in a list while [8:] will give us all the elements from the eighth to the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'Sense', 'and', 'Sensibility', 'by', 'Jane', 'Austen', '1811', ']', 'CHAPTER']\n",
      "['upon', 'us', ',', 'we', 'carried', 'forth', 'that', 'great', 'gift', 'of', 'freedom', 'and', 'delivered', 'it', 'safely', 'to', 'future', 'generations', '.', 'Thank', 'you', '.', 'God', 'bless', 'you', '.', 'And', 'God', 'bless', 'the', 'United', 'States', 'of', 'America', '.']\n"
     ]
    }
   ],
   "source": [
    "print(text2[:10])\n",
    "print(text4[145700:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help you understand how indexes work, let's create one.\n",
    "We start by defining the name of our index and then add the items. You probably won't do this in your own work, but you may want to manipulate an index in other ways. Pay attention to the quote marks and commas when you create your test sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "brown\n"
     ]
    }
   ],
   "source": [
    "sent = ['The', 'quick', 'brown', 'fox']\n",
    "print(sent[0])\n",
    "print(sent[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first element in the list is zero. This is because we are telling Python to go zero steps forward in the list. If we use an index that is too large (that is, we ask for something that doesn't exist), we'll get an error.\n",
    "We can modify elements in a list by assigning new data to one of its index values. We can also replace a slice with new material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'quick', 'furry', 'child']\n"
     ]
    }
   ],
   "source": [
    "sent[2] = 'furry'\n",
    "sent[3] = 'child'\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
